# -*- coding: utf-8 -*-
"""Convolution_Fashion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-iIEMH09uXl4fka6lNkasMBt0yhBYGe
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import tensorflow as tf
from tensorflow import keras

def to_categorical(y, num_classes):
    """One-hot encode a vector of class labels."""
    # We can use tf.keras.utils.to_categorical instead of custom function
    return tf.keras.utils.to_categorical(y, num_classes)

def load_data(train_file, test_file):
    # Load training data
    train_df = pd.read_csv(train_file)
    X_train = train_df.iloc[:, 1:].values.astype('float32')
    y_train_raw = train_df.iloc[:, 0].values.astype('int32')

    # Load test data
    test_df = pd.read_csv(test_file)
    X_test = test_df.iloc[:, 1:].values.astype('float32')
    y_test_raw = test_df.iloc[:, 0].values.astype('int32')

    # Normalize pixel values to [0, 1]
    X_train = X_train / 255.0
    X_test = X_test / 255.0

    # One-hot encode labels
    y_train = to_categorical(y_train_raw, num_classes=10)
    y_test = to_categorical(y_test_raw, num_classes=10)

    return (X_train, y_train, y_train_raw), (X_test, y_test, y_test_raw)

def plot_sample_images(images, labels, class_names, n=25):
    """Plot n sample images with their labels."""
    plt.figure(figsize=(10, 10))
    indices = np.random.choice(len(images), n, replace=False)
    for i, idx in enumerate(indices):
        plt.subplot(5, 5, i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(images[idx].reshape(28, 28), cmap=plt.cm.binary)
        plt.xlabel(class_names[np.argmax(labels[idx])])
    plt.tight_layout()
    plt.show()

def plot_predictions(X, y_true_onehot, model, class_names, n=25):
    """Plot images with their true and predicted labels."""
    plt.figure(figsize=(10, 10))
    indices = np.random.choice(len(X), n, replace=False)

    # Reshape for prediction if needed
    X_reshaped = X.reshape(-1, 28, 28, 1)

    # Get predictions
    y_pred = model.predict(X_reshaped)
    y_pred_classes = np.argmax(y_pred, axis=1)

    for i, idx in enumerate(indices):
        plt.subplot(5, 5, i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(X[idx].reshape(28, 28), cmap=plt.cm.binary)

        true_label = class_names[np.argmax(y_true_onehot[idx])]
        pred_label = class_names[y_pred_classes[idx]]
        color = 'green' if true_label == pred_label else 'red'
        plt.xlabel(f"True: {true_label}\nPred: {pred_label}", color=color)
    plt.tight_layout()
    plt.show()

def plot_learning_curves(history):
    """Plot learning curves for loss and accuracy."""
    plt.figure(figsize=(15, 5))

    # Plot loss curves
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train')
    plt.plot(history.history['val_loss'], label='Validation')
    plt.title('Loss Curve')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot accuracy curves
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Train')
    plt.plot(history.history['val_accuracy'], label='Validation')
    plt.title('Accuracy Curve')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

def plot_pixel_statistics(X_train, class_names, y_train_raw):
    """Plot mean and variance of pixel values across the Fashion MNIST dataset."""
    # Reshape images to 28x28
    X_images = X_train.reshape(-1, 28, 28)

    # Calculate global pixel statistics
    pixel_mean = np.mean(X_images, axis=0)
    pixel_variance = np.var(X_images, axis=0)

    plt.figure(figsize=(12, 5))

    # Plot pixel variance
    plt.subplot(1, 2, 2)
    plt.imshow(pixel_variance, cmap='plasma')
    plt.colorbar(label='Pixel Variance')
    plt.title('Pixel Variance Across All Images')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

def plot_class_pixel_means(X_train, class_names, y_train_raw):
    """Plot mean pixel values for each class in the dataset."""
    # Reshape images to 28x28
    X_images = X_train.reshape(-1, 28, 28)

    plt.figure(figsize=(15, 8))

    # For each class
    for i in range(10):
        # Get images for this class
        class_images = X_images[y_train_raw == i]

        # Calculate mean pixel values for this class
        class_mean = np.mean(class_images, axis=0)

        # Plot
        plt.subplot(2, 5, i+1)
        plt.imshow(class_mean, cmap='gray')
        plt.title(f'{class_names[i]}')
        plt.axis('off')

    plt.suptitle('Mean Image per Class', fontsize=16)
    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

def plot_pixel_intensity_distribution(X_train):
    """Plot distribution of pixel intensities in the dataset."""
    plt.figure(figsize=(10, 6))

    # Histogram of all pixel values
    plt.hist(X_train.flatten(), bins=50, alpha=0.7)
    plt.xlabel('Pixel Intensity')
    plt.ylabel('Frequency')
    plt.title('Distribution of Pixel Intensities')
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

def plot_pixel_activation_frequency(X_train):
    """Plot how frequently each pixel position is activated across the dataset."""
    # Reshape images to 28x28
    X_images = X_train.reshape(-1, 28, 28)

    # Consider a pixel "activated" if its value is above 0.3 (normalized data)
    activation_threshold = 0.3
    activation_map = np.mean(X_images > activation_threshold, axis=0)

    plt.figure(figsize=(8, 8))
    plt.imshow(activation_map, cmap='hot')
    plt.colorbar(label='Activation Frequency')
    plt.title('Pixel Activation Frequency')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

def plot_class_pixel_variances(X_train, class_names, y_train_raw):
    """Plot pixel variance for each class in the dataset."""
    # Reshape images to 28x28
    X_images = X_train.reshape(-1, 28, 28)

    plt.figure(figsize=(15, 8))

    # For each class
    for i in range(10):
        # Get images for this class
        class_images = X_images[y_train_raw == i]

        # Calculate variance of pixel values for this class
        class_variance = np.var(class_images, axis=0)

        # Plot
        plt.subplot(2, 5, i+1)
        plt.imshow(class_variance, cmap='viridis')
        plt.title(f'{class_names[i]}')
        plt.axis('off')

    plt.suptitle('Pixel Variance per Class', fontsize=16)
    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

def analyze_dataset(X_train, y_train_raw, class_names):
    """Run comprehensive data analysis on the Fashion MNIST dataset."""
    print(f"Dataset shape: {X_train.shape}")
    print(f"Number of classes: {len(class_names)}")

    # Count samples per class
    class_counts = np.bincount(y_train_raw)

    # Create class distribution plot
    plt.figure(figsize=(12, 5))
    plt.bar(class_names, class_counts)
    plt.title('Class Distribution in Training Set')
    plt.xlabel('Class')
    plt.ylabel('Number of Samples')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Plot pixel statistics
    plot_pixel_statistics(X_train, class_names, y_train_raw)

    # Plot class means
    plot_class_pixel_means(X_train, class_names, y_train_raw)

    # Plot class variances
    plot_class_pixel_variances(X_train, class_names, y_train_raw)

    # Plot pixel intensity distribution
    plot_pixel_intensity_distribution(X_train)

    # Plot pixel activation frequency
    plot_pixel_activation_frequency(X_train)

def create_cnn_model(input_shape, num_classes):
    """Create a CNN model using Keras Sequential API."""
    model = keras.models.Sequential()

    # First convolutional layer
    model.add(keras.layers.Conv2D(
        filters=32,
        kernel_size=(4, 4),
        activation='relu',
        input_shape=input_shape,
        name='conv2d_1'
    ))

    # Second convolutional layer
    model.add(keras.layers.Conv2D(
        filters=64,
        kernel_size=(3, 3),
        activation='relu',
        name='conv2d_2'
    ))

    # Max pooling layer
    model.add(keras.layers.MaxPooling2D(
        pool_size=(2, 2),
        name='max_pooling2d'
    ))

    # Dropout for regularization
    model.add(keras.layers.Dropout(
        rate=0.3,
        name='dropout_1'
    ))

    # Flatten the feature maps
    model.add(keras.layers.Flatten(
        name='flatten'
    ))

    # First fully connected (dense) layer
    model.add(keras.layers.Dense(
        units=128,
        activation='relu',
        name='dense_1'
    ))


    # More dropout
    model.add(keras.layers.Dropout(
        rate=0.5,
        name='dropout_2'
    ))

    # Output layer with softmax activation
    model.add(keras.layers.Dense(
        units=num_classes,
        activation='softmax',
        name='output'
    ))

    # Compile the model
    model.compile(
        loss='categorical_crossentropy',
        optimizer=keras.optimizers.Adam(),
        metrics=['accuracy']
    )

    return model

def create_feature_extraction_models(model):
    """Create models to extract features from each layer of the CNN."""
    layer_outputs = []
    layer_names = []

    # Get the output of each layer
    for layer in model.layers:
        # Skip dropout layers for visualization
        if 'dropout' not in layer.name:
            layer_outputs.append(layer.output)
            layer_names.append(layer.name)

    # Create feature extraction models
    feature_models = []
    for output, name in zip(layer_outputs, layer_names):
        feature_model = keras.models.Model(inputs=model.input, outputs=output)
        feature_models.append((feature_model, name))

    return feature_models

# def visualize_feature_maps(image, feature_models, class_names=None, true_label=None):
#     """Visualize feature maps for each layer in the CNN."""
#     # Reshape image for model input
#     input_image = image.reshape(1, 28, 28, 1)

#     plt.figure(figsize=(12, 8))

#     # First, show the original image
#     plt.subplot(1, len(feature_models) + 1, 1)
#     plt.imshow(image.reshape(28, 28), cmap='gray')
#     plt.title("Original Image")
#     if true_label is not None and class_names is not None:
#         plt.xlabel(f"Class: {class_names[true_label]}")
#     plt.axis('off')

#     # For each feature extraction model
#     for i, (feature_model, name) in enumerate(feature_models):
#         # Get feature maps
#         feature_maps = feature_model.predict(input_image)

#         # Handle different types of layers
#         if 'conv' in name:
#             # For convolutional layers, show a grid of feature maps
#             _, height, width, filters = feature_maps.shape
#             grid_size = int(np.ceil(np.sqrt(min(16, filters))))

#             # Create a grid to display first 16 feature maps
#             plt.subplot(1, len(feature_models) + 1, i + 2)
#             plt.title(f"{name} Output")

#             # Create a composite image of feature maps
#             composite = np.zeros((height * grid_size, width * grid_size))
#             for j in range(min(16, filters)):
#                 row = j // grid_size
#                 col = j % grid_size
#                 composite[row*height:(row+1)*height, col*width:(col+1)*width] = feature_maps[0, :, :, j]

#             plt.imshow(composite, cmap='viridis')
#             plt.axis('off')

#         elif 'max_pooling' in name:
#             # For max pooling layers
#             _, height, width, filters = feature_maps.shape
#             grid_size = int(np.ceil(np.sqrt(min(16, filters))))

#             plt.subplot(1, len(feature_models) + 1, i + 2)
#             plt.title(f"{name} Output")

#             # Create a composite image of feature maps
#             composite = np.zeros((height * grid_size, width * grid_size))
#             for j in range(min(16, filters)):
#                 row = j // grid_size
#                 col = j % grid_size
#                 composite[row*height:(row+1)*height, col*width:(col+1)*width] = feature_maps[0, :, :, j]

#             plt.imshow(composite, cmap='viridis')
#             plt.axis('off')

#         elif 'flatten' in name or 'dense' in name or 'output' in name:
#             # For fully connected layers, show bar chart of activations
#             plt.subplot(1, len(feature_models) + 1, i + 2)
#             plt.title(f"{name} Output")
#             plt.bar(range(min(20, feature_maps.shape[1])), feature_maps[0, :min(20, feature_maps.shape[1])])
#             plt.xlabel("Neuron")
#             plt.ylabel("Activation")

#     plt.tight_layout()
#     plt.show()

def visualize_kernels(model):
    """Visualize the convolutional kernels in the model."""
    # Get the convolutional layers
    conv_layers = [layer for layer in model.layers if 'conv' in layer.name]

    for layer in conv_layers:
        # Get weights - [kernel_weights, bias]
        weights = layer.get_weights()
        kernel_weights = weights[0]

        # Visualize kernels
        fig, axes = plt.subplots(8, 4, figsize=(12, 24))
        fig.suptitle(f'Kernels in {layer.name}', fontsize=16)

        # For each output channel (filter)
        for i in range(min(32, kernel_weights.shape[3])):
            # For each input channel
            ax = axes.flatten()[i]
            # Take the first input channel for visualization
            kernel = kernel_weights[:, :, 0, i]
            ax.imshow(kernel, cmap='viridis')
            ax.set_title(f'Filter {i+1}')
            ax.axis('off')

        plt.tight_layout()
        plt.subplots_adjust(top=0.95)
        plt.show()

def visualize_feature_maps(image, model, class_names=None, true_label=None):
    """Visualize feature maps showing how the image changes after each layer."""
    # Reshape image for model input
    input_image = image.reshape(1, 28, 28, 1)

    # Get all layer names in the model
    layer_names = [layer.name for layer in model.layers]

    # Create feature extraction models for each layer
    feature_models = []
    for i, layer_name in enumerate(layer_names):
        # This line has been changed
        feature_model = keras.models.Model(inputs=model.inputs, outputs=model.get_layer(layer_name).output)
        feature_models.append((feature_model, layer_name))

    # First, display the original image
    plt.figure(figsize=(20, 10))
    plt.subplot(1, 1, 1)
    plt.imshow(image.reshape(28, 28), cmap='gray')
    plt.title("Original Image")
    if true_label is not None and class_names is not None:
        plt.xlabel(f"Class: {class_names[true_label]}")
    plt.axis('off')
    plt.tight_layout()
    plt.show()

    # For each convolutional and pooling layer
    for feature_model, name in feature_models:
        if 'conv' in name or 'max_pooling' in name:
            # Get feature maps
            feature_maps = feature_model.predict(input_image)

            # Get dimensions of feature maps
            _, height, width, n_filters = feature_maps.shape

            # Create a figure to show feature maps
            n_cols = min(8, n_filters)
            n_rows = int(np.ceil(min(32, n_filters) / n_cols))

            plt.figure(figsize=(20, 10))
            plt.suptitle(f"Feature Maps after {name} - Shape: {height}x{width}x{n_filters}", fontsize=16)

            # Display up to 32 feature maps
            for i in range(min(32, n_filters)):
                plt.subplot(n_rows, n_cols, i+1)
                plt.imshow(feature_maps[0, :, :, i], cmap='viridis')
                plt.title(f"Filter {i+1}")
                plt.axis('off')

            plt.tight_layout()
            plt.subplots_adjust(top=0.9)
            plt.show()

def analyze_cnn_layers(model, X_test, y_test_raw, class_names, num_samples=3):
    """Analyze and visualize how images are transformed through CNN layers."""
    # Randomly select samples
    indices = np.random.choice(len(X_test), num_samples, replace=False)

    for idx in indices:
        image = X_test[idx]
        true_label = y_test_raw[idx]

        print(f"\n\nAnalyzing image with true label: {class_names[true_label]}")
        visualize_feature_maps(image, model, class_names, true_label)
def main():
    # Data preparation parameters
    batch_size = 128
    num_classes = 10
    epochs = 30

    # Input image dimensions
    img_rows, img_cols = 28, 28

    # Load data
    (X_train, y_train, y_train_raw), (X_test, y_test, y_test_raw) = load_data(
        "mnist_train.csv", "mnist_test.csv")

    # Class names
    class_names = ['0', '1', '2', '3', '4',
                   '5', '6', '7', '8', '9']

    # Run data analysis
    analyze_dataset(X_train, y_train_raw, class_names)

    # Visualize samples
    plot_sample_images(X_train, y_train, class_names)

    # Reshape data for CNN input (height, width, channels)
    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

    print(f"X_train shape: {X_train.shape}")
    print(f"{X_train.shape[0]} train samples")
    print(f"{X_test.shape[0]} test samples")

    # Create and train the model
    model = create_cnn_model(input_shape, num_classes)

    # Display model summary
    model.summary()

    # Train the model with validation split
    history = model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=epochs,
        validation_split=0.2,
        verbose=1
    )

    # Evaluate the model
    scores = model.evaluate(X_test, y_test, verbose=0)
    print(f"Test loss: {scores[0]}")
    print(f"Test accuracy: {scores[1]}")

    # Learning curves
    plot_learning_curves(history)

    # Confusion matrix
    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    cm = confusion_matrix(y_test_raw, y_pred_classes)
    disp = ConfusionMatrixDisplay(cm, display_labels=class_names)
    disp.plot(xticks_rotation=90)
    plt.title("Confusion Matrix")
    plt.tight_layout()
    plt.show()

    # Sample predictions
    plot_predictions(X_test, y_test, model, class_names)

    # Visualize kernels of convolutional layers
    # visualize_kernels(model)

    # Visualize feature maps for sample test images
    analyze_cnn_layers(model, X_test, y_test_raw, class_names, num_samples=3)

if __name__ == "__main__":
    main()

from google.colab import drive
drive.mount('/content/drive')